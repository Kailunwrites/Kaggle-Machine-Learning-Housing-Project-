'X1stFlrSF',
'X2ndFlrSF',
'LowQualFinSF',
'GrLivArea',
'GarageYrBlt',
'GarageArea',
'WoodDeckSF',
'OpenPorchSF',
'EnclosedPorch',
'X3SsnPorch',
'ScreenPorch',
'PoolArea'
)
#Transform continuous variable if skewed
for (var in cont_var) {
skew = abs(skewness(orig_cont[var]))
if (skew > 0.7) {
orig_cont[var] = log(orig_cont[var] + 1) #0.7 arbitrary
}
}
#Center Data
preProcess(orig_cont,method = c("center", "scale"))
library(caret)    #ML
#Add non-categorical variables from featured dataset to original dataset
df1 = hp_orig %>% select(-GarageCars)
df2 = hp_feat %>% select(TotalSF, Age, AgeRemod, TotPorchSF, TotCarGarage, TotBaths)
orig_cont = cbind.data.frame(df1, df2)
#Transform continuous data if skewed
cont_var = c(
'LotFrontage',
'LotArea',
'MasVnrArea',
'BsmtFinSF1',
'BsmtFinSF2',
'BsmtUnfSF',
'TotalBsmtSF',
'X1stFlrSF',
'X2ndFlrSF',
'LowQualFinSF',
'GrLivArea',
'GarageYrBlt',
'GarageArea',
'WoodDeckSF',
'OpenPorchSF',
'EnclosedPorch',
'X3SsnPorch',
'ScreenPorch',
'PoolArea'
)
#Transform continuous variable if skewed
for (var in cont_var) {
skew = abs(skewness(orig_cont[var]))
if (skew > 0.7) {
orig_cont[var] = log(orig_cont[var] + 1) #0.7 arbitrary
}
}
#Center Data
preProcess(orig_cont,method = c("center", "scale"))
#Prepare predictor and response matrices
predictors_train = data.matrix(orig_cont %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(orig_cont %>% select(SalePrice_log, -Id))    #must be matrix
#1st model: original data, no hypertuning
xgb.orig_trans = xgb.cv(
data = predictors_train,     #Predictor variables
label = response_train,      #Response variable
nrounds = 1000,              #Num of trees
nfold = 5,                   #Number of folds (~5-10)
objective = "reg:linear",    #Linear regression
verbose = 0,                 #No output
early_stopping_rounds = 20,  #haults CV if MSE doesn't improve after 10 trees
)
#Calculate RMSE of train and test
#RMSE_train = ~ 0.002358
#RMSE_test = ~ 0.1314094
xgb.orig_trans$evaluation_log %>%
summarise(rmse_train = min(train_rmse_mean),
rmse_test = min(test_rmse_mean),
)
#Plot RMSE vs Number of Trees
ggplot(xgb.orig_trans$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Featured Transformed Dataset: Train RMSE vs. Number of Trees') +
coord_cartesian(ylim = c(0, .2))
#Add non-categorical variables from featured dataset to original dataset
df1 = hp_orig %>% select(-GarageCars)
df2 = hp_feat %>% select(TotalSF, Age, AgeRemod, TotPorchSF, TotCarGarage, TotBaths)
orig_cont = cbind.data.frame(df1, df2)
#Transform continuous data if skewed
cont_var = c(
'LotFrontage',
'LotArea',
'MasVnrArea',
'BsmtFinSF1',
'BsmtFinSF2',
'BsmtUnfSF',
'TotalBsmtSF',
'X1stFlrSF',
'X2ndFlrSF',
'LowQualFinSF',
'GrLivArea',
'GarageYrBlt',
'GarageArea',
'WoodDeckSF',
'OpenPorchSF',
'EnclosedPorch',
'X3SsnPorch',
'ScreenPorch',
'PoolArea'
)
#Transform continuous variable if skewed
for (var in cont_var) {
skew = abs(skewness(orig_cont[var]))
if (skew > 0.7) {
orig_cont[var] = log(orig_cont[var] + 1) #0.7 arbitrary
}
preProcess(orig_cont[var],method = c("center", "scale"))
}
#Prepare predictor and response matrices
predictors_train = data.matrix(orig_cont %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(orig_cont %>% select(SalePrice_log, -Id))    #must be matrix
#1st model: original data, no hypertuning
xgb.orig_trans = xgb.cv(
data = predictors_train,     #Predictor variables
label = response_train,      #Response variable
nrounds = 1000,              #Num of trees
nfold = 5,                   #Number of folds (~5-10)
objective = "reg:linear",    #Linear regression
verbose = 0,                 #No output
early_stopping_rounds = 20,  #haults CV if MSE doesn't improve after 10 trees
)
#Calculate RMSE of train and test
#RMSE_train = ~ 0.002358
#RMSE_test = ~ 0.1314094
xgb.orig_trans$evaluation_log %>%
summarise(rmse_train = min(train_rmse_mean),
rmse_test = min(test_rmse_mean),
)
#Plot RMSE vs Number of Trees
ggplot(xgb.orig_trans$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Featured Transformed Dataset: Train RMSE vs. Number of Trees') +
coord_cartesian(ylim = c(0, .2))
#Add non-categorical variables from featured dataset to original dataset
df1 = hp_orig %>% select(-GarageCars)
df2 = hp_feat %>% select(TotalSF, Age, AgeRemod, TotPorchSF, TotCarGarage, TotBaths)
orig_cont = cbind.data.frame(df1, df2)
#Transform continuous data if skewed
cont_var = c(
'LotFrontage',
'LotArea',
'MasVnrArea',
'BsmtFinSF1',
'BsmtFinSF2',
'BsmtUnfSF',
'TotalBsmtSF',
'X1stFlrSF',
'X2ndFlrSF',
'LowQualFinSF',
'GrLivArea',
'GarageYrBlt',
'GarageArea',
'WoodDeckSF',
'OpenPorchSF',
'EnclosedPorch',
'X3SsnPorch',
'ScreenPorch',
'PoolArea'
)
#Transform continuous variable if skewed
for (var in cont_var) {
skew = abs(skewness(orig_cont[var]))
if (skew > 0.7) {
orig_cont[var] = log(orig_cont[var] + 1) #0.7 arbitrary
}
}
#Prepare predictor and response matrices
predictors_train = data.matrix(orig_cont %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(orig_cont %>% select(SalePrice_log, -Id))    #must be matrix
#1st model: original data, no hypertuning
xgb.orig_trans = xgb.cv(
data = predictors_train,     #Predictor variables
label = response_train,      #Response variable
nrounds = 1000,              #Num of trees
nfold = 5,                   #Number of folds (~5-10)
objective = "reg:linear",    #Linear regression
verbose = 0,                 #No output
early_stopping_rounds = 20,  #haults CV if MSE doesn't improve after 10 trees
)
#Calculate RMSE of train and test
#RMSE_train = ~ 0.002358
#RMSE_test = ~ 0.1314094
xgb.orig_trans$evaluation_log %>%
summarise(rmse_train = min(train_rmse_mean),
rmse_test = min(test_rmse_mean),
)
#Plot RMSE vs Number of Trees
ggplot(xgb.orig_trans$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Featured Transformed Dataset: Train RMSE vs. Number of Trees') +
coord_cartesian(ylim = c(0, .2))
#Prepare predictor and response matrices
predictors_train = data.matrix(orig_cont %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(orig_cont %>% select(SalePrice_log, -Id))    #must be matrix
#Create hypergrid of hyperparameters to tune
hyper_grid <- expand.grid(
eta = c(.005, .01),           #learning rate
max_depth = c(4,6),           #min weight sum required in a child
min_child_weight = c(4,6),    #max depth of trees
subsample = c(.25, .75),           #ratio of training predictors
colsample_bytree = c(.9, 1),     #subsample ratio per tree
alpha = 0                            #L1 lasso penalization
)
#Perform Grid Search
for(i in 1:nrow(hyper_grid)) {
#Create parameter list based on iterative hyper grid inputs
params = list(
eta = hyper_grid$eta[i],
max_depth = hyper_grid$max_depth[i],
min_child_weight = hyper_grid$min_child_weight[i],
subsample = hyper_grid$subsample[i],
colsample_bytree = hyper_grid$colsample_bytree[i],
alpha = hyper_grid$alpha[i]
)
#Cross-Valication
xgb.orig_tran_tune = xgb.cv(
params = params,
data = predictors_train,     #Predictor variables
label = response_train,      #Response variable
nrounds = 1000,              #Num of trees
nfold = 5,                   #Number of folds (~5-10)
objective = "reg:linear",    #Linear regression
verbose = 0,                 #No output
early_stopping_rounds = 20,  #haults CV if MSE doesn't improve after 10 trees
)
# add min training error and trees to grid
hyper_grid$optimal_trees[i] <- which.min(xgb.orig_tran_tune$evaluation_log$test_rmse_mean)
hyper_grid$min_RMSE[i] <- min(xgb.orig_tran_tune$evaluation_log$test_rmse_mean)
}
#Prepare predictor and response matrices
predictors_train = data.matrix(orig_cont %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(orig_cont %>% select(SalePrice_log, -Id))    #must be matrix
#Create hypergrid of hyperparameters to tune
hyper_grid <- expand.grid(
eta = c(.005, .01),           #learning rate
max_depth = c(4,6),           #min weight sum required in a child
min_child_weight = c(4,6),    #max depth of trees
subsample = c(.25, .75),           #ratio of training predictors
colsample_bytree = c(.9, 1),     #subsample ratio per tree
alpha = 0                            #L1 lasso penalization
)
nrow(hyper_grid)
#Prepare predictor and response matrices
predictors_train = data.matrix(orig_cont %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(orig_cont %>% select(SalePrice_log, -Id))    #must be matrix
#Create hypergrid of hyperparameters to tune
hyper_grid <- expand.grid(
eta = c(.005, .01),           #learning rate
max_depth = c(4,6),           #min weight sum required in a child
min_child_weight = c(4,6),    #max depth of trees
subsample = c(.25, .75),           #ratio of training predictors
colsample_bytree = c(.9, 1),     #subsample ratio per tree
alpha = 0                            #L1 lasso penalization
)
nrow(hyper_grid)
#Perform Grid Search
for(i in 1:nrow(hyper_grid)) {
#Create parameter list based on iterative hyper grid inputs
params = list(
eta = hyper_grid$eta[i],
max_depth = hyper_grid$max_depth[i],
min_child_weight = hyper_grid$min_child_weight[i],
subsample = hyper_grid$subsample[i],
colsample_bytree = hyper_grid$colsample_bytree[i],
alpha = hyper_grid$alpha[i]
)
#Cross-Valication
xgb.orig_tran_tune = xgb.cv(
params = params,
data = predictors_train,     #Predictor variables
label = response_train,      #Response variable
nrounds = 1000,              #Num of trees
nfold = 5,                   #Number of folds (~5-10)
objective = "reg:linear",    #Linear regression
verbose = 1,                 #No output
early_stopping_rounds = 10,  #haults CV if MSE doesn't improve after 10 trees
)
# add min training error and trees to grid
hyper_grid$optimal_trees[i] <- which.min(xgb.orig_tran_tune$evaluation_log$test_rmse_mean)
hyper_grid$min_RMSE[i] <- min(xgb.orig_tran_tune$evaluation_log$test_rmse_mean)
}
hyper_grid %>% arrange(min_RMSE) %>% head(10)
#Prepare predictor and response matrices
predictors_train = data.matrix(orig_cont %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(orig_cont %>% select(SalePrice_log, -Id))    #must be matrix
#Create hypergrid of hyperparameters to tune
hyper_grid <- expand.grid(
eta = c(0.01),           #learning rate
max_depth = c(4),           #min weight sum required in a child
min_child_weight = c(4),    #max depth of trees
subsample = c(.25),           #ratio of training predictors
colsample_bytree = c(1),     #subsample ratio per tree
alpha = c(0.01, 0.1, 1, 10, 100, 1000)                            #L1 lasso penalization
)
nrow(hyper_grid)
#Perform Grid Search
for(i in 1:nrow(hyper_grid)) {
#Create parameter list based on iterative hyper grid inputs
params = list(
eta = hyper_grid$eta[i],
max_depth = hyper_grid$max_depth[i],
min_child_weight = hyper_grid$min_child_weight[i],
subsample = hyper_grid$subsample[i],
colsample_bytree = hyper_grid$colsample_bytree[i],
alpha = hyper_grid$alpha[i]
)
#Cross-Valication
xgb.orig_tran_tune = xgb.cv(
params = params,
data = predictors_train,     #Predictor variables
label = response_train,      #Response variable
nrounds = 1000,              #Num of trees
nfold = 5,                   #Number of folds (~5-10)
objective = "reg:linear",    #Linear regression
verbose = 1,                 #No output
early_stopping_rounds = 10,  #haults CV if MSE doesn't improve after 10 trees
)
# add min training error and trees to grid
hyper_grid$min_trees[i] <- which.min(xgb.orig_tran_tune$evaluation_log$test_rmse_mean)
hyper_grid$min_RMSE[i] <- min(xgb.orig_tran_tune$evaluation_log$test_rmse_mean)
}
hyper_grid %>% arrange(min_RMSE) %>% head(10)
#Prepare predictor and response matrices
predictors_train = data.matrix(orig_cont %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(orig_cont %>% select(SalePrice_log, -Id))    #must be matrix
#Create hypergrid of hyperparameters to tune
hyper_grid <- expand.grid(
eta = c(0.01, 0.001),           #learning rate
max_depth = c(3,4),           #min weight sum required in a child
min_child_weight = c(3,4),    #max depth of trees
subsample = c(0.20, .25),           #ratio of training predictors
colsample_bytree = c(1),     #subsample ratio per tree
alpha = c(0.01, 0.1, 0.5)                            #L1 lasso penalization
)
nrow(hyper_grid)
#Perform Grid Search
for(i in 1:nrow(hyper_grid)) {
#Create parameter list based on iterative hyper grid inputs
params = list(
eta = hyper_grid$eta[i],
max_depth = hyper_grid$max_depth[i],
min_child_weight = hyper_grid$min_child_weight[i],
subsample = hyper_grid$subsample[i],
colsample_bytree = hyper_grid$colsample_bytree[i],
alpha = hyper_grid$alpha[i]
)
#Cross-Valication
xgb.orig_tran_tune = xgb.cv(
params = params,
data = predictors_train,     #Predictor variables
label = response_train,      #Response variable
nrounds = 5000,              #Num of trees
nfold = 5,                   #Number of folds (~5-10)
objective = "reg:linear",    #Linear regression
verbose = 1,                 #No output
early_stopping_rounds = 10,  #haults CV if MSE doesn't improve after 10 trees
)
# add min training error and trees to grid
hyper_grid$min_trees[i] <- which.min(xgb.orig_tran_tune$evaluation_log$test_rmse_mean)
hyper_grid$min_RMSE[i] <- min(xgb.orig_tran_tune$evaluation_log$test_rmse_mean)
}
hyper_grid %>% arrange(min_RMSE) %>% head(10)
#0.01, 4, 4, 0.25, 1, 1e-1 = 0.1153540
i = 1
hyper_grid = hyper_grid %>% arrange(min_RMSE) %>% head(10)
store[i] = hyper_grid[1,]
store = data.frame()
sotre
store
hyper_grid = hyper_grid %>% arrange(min_RMSE) %>% head(10)
store[i] = hyper_grid[1,]
i = i + 1
store
store = data.frame()
i
i = 1
hyper_grid = hyper_grid %>% arrange(min_RMSE) %>% head(10)
store[i,] = hyper_grid[1,]
store
hyper_grid[1,]
hyper_grid <- expand.grid(
eta = c(0.005, 0.01),           #learning rate
max_depth = c(3,4,5),           #min weight sum required in a child
min_child_weight = c(3,4),    #max depth of trees
subsample = c(0.20, .3),           #ratio of training predictors
colsample_bytree = c(1),     #subsample ratio per tree
alpha = c(0.005, 0.01)                            #L1 lasso penalization
)
nrow(hyper_grid)
#Prepare predictor and response matrices
predictors_train = data.matrix(orig_cont %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(orig_cont %>% select(SalePrice_log, -Id))    #must be matrix
#Create hypergrid of hyperparameters to tune
hyper_grid <- expand.grid(
eta = c(0.005, 0.01),           #learning rate
max_depth = c(3,4,5),           #min weight sum required in a child
min_child_weight = c(3,4),    #max depth of trees
subsample = c(0.20, .3),           #ratio of training predictors
colsample_bytree = c(1),     #subsample ratio per tree
alpha = c(0.005, 0.01)                            #L1 lasso penalization
)
nrow(hyper_grid)
#Perform Grid Search
for(i in 1:nrow(hyper_grid)) {
#Create parameter list based on iterative hyper grid inputs
params = list(
eta = hyper_grid$eta[i],
max_depth = hyper_grid$max_depth[i],
min_child_weight = hyper_grid$min_child_weight[i],
subsample = hyper_grid$subsample[i],
colsample_bytree = hyper_grid$colsample_bytree[i],
alpha = hyper_grid$alpha[i]
)
# ========================================================
# min_RMSE = 0.1124
# ========================================================
# params = list(
#   eta = 0.01,
#   max_depth = 4,
#   min_child_weight = 3,
#   subsample = 0.25,
#   colsample_bytree = 1,
#   alpha = 0.01,
#   nrounds = 1207,
# )
# ========================================================
#Cross-Valication
xgb.orig_tran_tune = xgb.cv(
params = params,
data = predictors_train,     #Predictor variables
label = response_train,      #Response variable
nrounds = 2000,              #Num of trees
nfold = 5,                   #Number of folds (~5-10)
objective = "reg:linear",    #Linear regression
verbose = 1,                 #No output
early_stopping_rounds = 10,  #haults CV if MSE doesn't improve after 10 trees
)
# add min training error and trees to grid
hyper_grid$min_trees[i] <- which.min(xgb.orig_tran_tune$evaluation_log$test_rmse_mean)
hyper_grid$min_RMSE[i] <- min(xgb.orig_tran_tune$evaluation_log$test_rmse_mean)
}
hyper_grid = hyper_grid %>% arrange(min_RMSE) %>% head(10)
store[i,] = hyper_grid[1,]
i = i + 1
store
hyper_grid
load('train_all.RData')
original_data = read.csv2('train.csv')
original_data = read.csv2('train.csv', header=T)
original_data = read.csv2('train.csv', header=T)
View(original_data)
original_data = read.csv2('train.csv', header=T, sep = ',')
View(original_data)
mean(isna(original_data$LotFrontage))
mean(is.na(original_data$LotFrontage))
is.na(original_data$LotFrontage)
origial_data %>% group_by(Neighborhood) %>% summarise(mean_LotFrontage = mean(LotFrontage))
original_data %>% group_by(Neighborhood) %>% summarise(mean_LotFrontage = mean(LotFrontage))
original_data %>% group_by(Neighborhood) %>% summarise(mean_LotFrontage = mean(LotFrontage, na.rm=T))
summary = original_data %>% group_by(Neighborhood) %>% summarise(mean_LotFrontage = mean(LotFrontage, na.rm=T))
index(is.na(original_data$LotFrontage))
original_data$LotFrontage[is.na(original_data$LotFrontage),]
original_data$LotFrontage[is.na(original_data$LotFrontage)]
which(is.na(original_data$LotFrontage))
for (neigh in Neighborhood){
print(neigh)
}
for (neigh in original_data$Neighborhood){
print(neigh)
}
neigh = "Edwards"
neigh = "Edwards"
which(is.na(original_data$LotFrontage) & (original_data$Neighborhood==neigh))
impute_LotFrontage = original_data$LotFrontage
original_data %>% filter(Neighborhood == neigh) %>% summarise(mean(LotFrontage, na.rm=T)
original_data %>% filter(Neighborhood == neigh) %>% summarise(mean(LotFrontage, na.rm=T))
original_data %>% filter(Neighborhood == neigh) %>% summarise(mean(LotFrontage, na.rm=T))
test = original_data %>% filter(Neighborhood == neigh) %>% summarise(mean(LotFrontage, na.rm=T))
test[1]
test = original_data %>% filter(Neighborhood == neigh) %>% summarise(mean(LotFrontage, na.rm=T))
test[1]
test = original_data %>% filter(Neighborhood == neigh) %>% summarise(mean(LotFrontage, na.rm=T))
value(test)
test
original_data$LotFrontage[ original_data$Neighborhood==neigh]
load('train_all.RData')
original_data = read.csv2('train.csv', header=T, sep = ',')
impute_LotFrontage = original_data$LotFrontage
for (neigh in original_data$Neighborhood){
idx = which(is.na(original_data$LotFrontage) & (original_data$Neighborhood==neigh))
impute_LotFrontage[idx] =  mean(original_data$LotFrontage[original_data$Neighborhood==neigh], na.rm=T)
}
is.na(impute_LotFrontage)
sum(is.na(impute_LotFrontage))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set directory
load('train_all.RData') #load original and featured-engineered datasets
hp_feat = hp_feat %>% select(-SalePrice) #remove ID and sales price
hp_orig = hp_orig %>% rename(SalePrice = SalePrice_y, SalePrice_log = SalePrice_log_y) %>%
select(-SalePrice) #correct name from merging datasets
save(hp_feat, hp_orig, file = "train_all_v2.RData")
