xgb.feat$evaluation_log %>%
summarise(rmse_train = min(train_rmse_mean),
rmse_test = min(test_rmse_mean))
#Plot RMSE vs Number of Trees
ggplot(xgb.feat$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Feature-Engineer Dataset: Train RMSE vs. Number of Trees')
#Create model XGBoost model
xgb.feat_test <- xgboost(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
)
#Plot variable importance of 'test' subset of train data
importance_mat.feat = xgb.importance(model = xgb.feat_test) #create matrix
xgb.plot.importance(importance_mat.feat, top_n = 20, measure = "Gain")
#Predict SalePrice_log of 'test' subset of train data
test_df = data.matrix(hp_feat[-train_idx, ] %>% select(-Id, -SalePrice_log)) #isolate test data
xgb_pred.feat = predict(xgb.feat_test, test_df) #predict saleprice_log
#Calculate MSE of 'test' subset of train data
#MSE = 2.128978e-06
MSE.feat = mean((xgb_pred.feat - hp_feat$SalePrice_log[-train_idx]) ^ 2)
MSE.feat
#How much is the prediction price off from the actual 'test' price?
pred_dol = exp(xgb_pred.feat) #predicted house price [$]
act_dol = exp(hp_feat$SalePrice_log[-train_idx]) #actual house price (test subset of training dataset) [$]
mean(abs(pred_dol - act_dol))
#Prepare predictor and response matrices
predictors_train = data.matrix(hp_orig %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(hp_orig %>% select(SalePrice_log, -Id))    #must be matrix
#2nd model: original data, no hypertuning
xgb.orig <- xgb.cv(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
early_stopping_rounds = 10    #haults CV if MSE doesn't improve
)
#Calculate RMSE of train and test
#RMSE_train = ~0.018571
#RMSE_test = ~0.135167
xgb.orig$evaluation_log %>%
summarise(rmse_train = min(train_rmse_mean),
rmse_test = min(test_rmse_mean),)
#Plot RMSE vs Number of Trees
ggplot(xgb.orig$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Original Dataset: Train RMSE vs. Number of Trees')
#Create model XGBoost model
xgb.orig_test <- xgboost(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
)
#Plot variable importance of 'test' subset of train data
importance_mat.orig = xgb.importance(model = xgb.orig_test) #create matrix
xgb.plot.importance(importance_mat.orig, top_n = 20, measure = "Gain")
#Predict SalePrice_log of 'test' subset of train data
test_df = data.matrix(hp_orig[-train_idx, ] %>% select(-Id, -SalePrice_log)) #isolate test data
xgb_pred.orig = predict(xgb.orig_test, test_df) #predict saleprice_log
#Calculate MSE of 'test' subset of train data
#MSE.orig = 1.555677e-06
MSE.orig = mean((xgb_pred.orig - hp_orig$SalePrice_log[-train_idx]) ^ 2)
MSE.orig
#How much is the prediction price off from the actual 'test' price?
pred_dol = exp(xgb_pred.orig) #predicted house price [$]
act_dol = exp(hp_orig$SalePrice_log[-train_idx]) #actual house price (test subset of training dataset) [$]
mean(abs(pred_dol - act_dol))
#Previously, model2 (orig df) outperformed model1 (df)
#Want to combine to maximize best columns
uniq = c(setdiff(names(hp_feat), names(hp_orig)), 'Id')
combined = merge(hp_orig, hp_feat[uniq], by = 'Id')
combined_train = combined[train_idx, ]
#Prep Feature and Response Data
predictors_train = data.matrix(combined_train %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(combined_train %>% select(SalePrice_log, -Id))    #must be matrix
#3rd Model: Combined Variables, No Hyperparameter Tuning
xgb.comb <- xgb.cv(
data = predictors_train,
label = response_train,
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
early_stopping_rounds = 10    #haults CV if MSE doesn't improve
)
#Calculate RMSE of train and test
#RMSE_train = ~0.0212704
#RMSE_test = ~0.1369496
xgb.comb$evaluation_log %>%
summarise(rmse_train   = min(train_rmse_mean),
rmse_test   = min(test_rmse_mean),)
#Plot RMSE vs Number of Trees
ggplot(xgb.orig$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Combined Dataset: Train RMSE vs. Number of Trees')
#Create model XGBoost model
xgb.comb_test <- xgboost(
data = predictors_train,
label = response_train,
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
)
#Plot variable importance of 'test' subset of train data
importance_mat.comb = xgb.importance(model = xgb.comb_test)
xgb.plot.importance(importance_mat.comb, top_n = 20, measure = "Gain")
#Predict SalePrice_log of 'test' subset of train data
test_df = data.matrix(combined[-train_idx, ] %>% select(-Id, -SalePrice_log))
xgb_pred.comb = predict(xgb.comb_test, test_df)
#Calculate MSE of 'test' subset of train data
#MSE.comb = 0.01627476
MSE.comb = mean((xgb_pred.comb - combined$SalePrice_log[-train_idx]) ^ 2)
MSE.comb
#How much is the prediction price off from the actual 'test' price?
pred_dol = exp(xgb_pred.comb) #predicted house price [$]
act_dol = exp(combined$SalePrice_log[-train_idx]) #actual house price (test subset of training dataset) [$]
mean(abs(pred_dol - act_dol))
importance_mat.feat[,1]
imp_feat = paste(importance_mat.feat[,1], importance_mat.orig[,1])
View(imp_feat)
imp_feat = [importance_mat.feat[,1], importance_mat.orig[,1]]
imp_feat = merge(importance_mat.feat[,1], importance_mat.orig[,1])
importance_mat.feat[,1] + importance_mat.orig[,1]
imp_feat = data.frame(importance_mat.feat[,1], importance_mat.orig[,1])
imp_feat = data.frame(importance_mat.feat[1:20,1], importance_mat.orig[1:20,1])
names(imp_feat) = c('feat_data','orig_data')
imp_feat = data.frame(importance_mat.feat[1:20,1], importance_mat.orig[1:20,1], importance_mat.comb[1:20,1])
names(imp_feat) = c('feat_data','orig_data', 'comb_data')
#Prepare predictor and response matrices
predictors_train = data.matrix(hp_feat %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(hp_feat %>% select(SalePrice_log, -Id))    #must be matrix
#2nd model: original data, no hypertuning
xgb.feat <- xgb.cv(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
early_stopping_rounds = 10    #haults CV if MSE doesn't improve
)
#Calculate RMSE of train and test
#RMSE_train = ~0.037697
#RMSE_test = ~0.1365288
xgb.feat$evaluation_log %>%
summarise(rmse_train = min(train_rmse_mean),
rmse_test = min(test_rmse_mean))
#Plot RMSE vs Number of Trees
ggplot(xgb.feat$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Feature-Engineer Dataset: Train RMSE vs. Number of Trees')
#Create model XGBoost model
xgb.feat_test <- xgboost(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
)
#Plot variable importance of 'test' subset of train data
importance_mat.feat = xgb.importance(model = xgb.feat_test) #create matrix
xgb.plot.importance(importance_mat.feat, top_n = 20, measure = "Gain")
#Predict SalePrice_log of 'test' subset of train data
test_df = data.matrix(hp_feat[-train_idx, ] %>% select(-Id, -SalePrice_log)) #isolate test data
xgb_pred.feat = predict(xgb.feat_test, hp_feat) #predict saleprice_log
#Prepare predictor and response matrices
predictors_train = data.matrix(hp_feat %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(hp_feat %>% select(SalePrice_log, -Id))    #must be matrix
#2nd model: original data, no hypertuning
xgb.feat <- xgb.cv(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
early_stopping_rounds = 10    #haults CV if MSE doesn't improve
)
#Calculate RMSE of train and test
#RMSE_train = ~0.037697
#RMSE_test = ~0.1365288
xgb.feat$evaluation_log %>%
summarise(rmse_train = min(train_rmse_mean),
rmse_test = min(test_rmse_mean))
#Plot RMSE vs Number of Trees
ggplot(xgb.feat$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Feature-Engineer Dataset: Train RMSE vs. Number of Trees')
#Create model XGBoost model
xgb.feat_test <- xgboost(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
)
#Plot variable importance of 'test' subset of train data
importance_mat.feat = xgb.importance(model = xgb.feat_test) #create matrix
xgb.plot.importance(importance_mat.feat, top_n = 20, measure = "Gain")
#Predict SalePrice_log of 'test' subset of train data
test_df = data.matrix(hp_feat[-train_idx, ] %>% select(-Id, -SalePrice_log)) #isolate test data
xgb_pred.feat = predict(xgb.feat_test, data.martrix(hp_feat)) #predict saleprice_log
#Prepare predictor and response matrices
predictors_train = data.matrix(hp_feat %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(hp_feat %>% select(SalePrice_log, -Id))    #must be matrix
#2nd model: original data, no hypertuning
xgb.feat <- xgb.cv(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
early_stopping_rounds = 10    #haults CV if MSE doesn't improve
)
#Calculate RMSE of train and test
#RMSE_train = ~0.037697
#RMSE_test = ~0.1365288
xgb.feat$evaluation_log %>%
summarise(rmse_train = min(train_rmse_mean),
rmse_test = min(test_rmse_mean))
#Plot RMSE vs Number of Trees
ggplot(xgb.feat$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Feature-Engineer Dataset: Train RMSE vs. Number of Trees')
#Create model XGBoost model
xgb.feat_test <- xgboost(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
)
#Plot variable importance of 'test' subset of train data
importance_mat.feat = xgb.importance(model = xgb.feat_test) #create matrix
xgb.plot.importance(importance_mat.feat, top_n = 20, measure = "Gain")
#Predict SalePrice_log of 'test' subset of train data
test_df = data.matrix(hp_feat[-train_idx, ] %>% select(-Id, -SalePrice_log)) #isolate test data
xgb_pred.feat = predict(xgb.feat_test, data.matrix(hp_feat)) #predict saleprice_log
#Prepare predictor and response matrices
predictors_train = data.matrix(hp_feat %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(hp_feat %>% select(SalePrice_log, -Id))    #must be matrix
#2nd model: original data, no hypertuning
xgb.feat <- xgb.cv(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
early_stopping_rounds = 10    #haults CV if MSE doesn't improve
)
#Calculate RMSE of train and test
#RMSE_train = ~0.037697
#RMSE_test = ~0.1365288
xgb.feat$evaluation_log %>%
summarise(rmse_train = min(train_rmse_mean),
rmse_test = min(test_rmse_mean))
#Plot RMSE vs Number of Trees
ggplot(xgb.feat$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Feature-Engineer Dataset: Train RMSE vs. Number of Trees')
#Create model XGBoost model
xgb.feat_test <- xgboost(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
)
#Plot variable importance of 'test' subset of train data
importance_mat.feat = xgb.importance(model = xgb.feat_test) #create matrix
xgb.plot.importance(importance_mat.feat, top_n = 20, measure = "Gain")
#Predict SalePrice_log of 'test' subset of train data
test_df = data.matrix(hp_feat[-train_idx, ] %>% select(-Id, -SalePrice_log)) #isolate test data
xgb_pred.feat = predict(xgb.feat_test, data.matrix(hp_feat %>% select(-SalePrice_log, -Id)) #predict saleprice_log
#Calculate MSE of 'test' subset of train data
#MSE = 2.128978e-06
MSE.feat = mean((xgb_pred.feat - hp_feat$SalePrice_log) ^ 2)
xgb_pred.feat = predict(xgb.feat_test, data.matrix(hp_feat %>% select(-SalePrice_log, -Id)) #predict saleprice_log
#Calculate MSE of 'test' subset of train data
#MSE = 2.128978e-06
MSE.feat = mean((xgb_pred.feat - hp_feat$SalePrice_log) ^ 2)
mean((xgb_pred.feat - hp_feat$SalePrice_log) ^ 2)
#Prepare predictor and response matrices
predictors_train = data.matrix(hp_feat %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(hp_feat %>% select(SalePrice_log, -Id))    #must be matrix
#2nd model: original data, no hypertuning
xgb.feat <- xgb.cv(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
early_stopping_rounds = 10    #haults CV if MSE doesn't improve
)
#Calculate RMSE of train and test
#RMSE_train = ~0.037697
#RMSE_test = ~0.1365288
xgb.feat$evaluation_log %>%
summarise(rmse_train = min(train_rmse_mean),
rmse_test = min(test_rmse_mean))
#Plot RMSE vs Number of Trees
ggplot(xgb.feat$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Feature-Engineer Dataset: Train RMSE vs. Number of Trees')
#Create model XGBoost model
xgb.feat_test <- xgboost(
data = predictors_train,
#Predictor variables
label = response_train,
#Response variable
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
)
#Plot variable importance of 'test' subset of train data
importance_mat.feat = xgb.importance(model = xgb.feat_test) #create matrix
xgb.plot.importance(importance_mat.feat, top_n = 20, measure = "Gain")
#Predict SalePrice_log of 'test' subset of train data
test_df = data.matrix(hp_feat[-train_idx, ] %>% select(-Id, -SalePrice_log)) #isolate test data
xgb_pred.feat = predict(xgb.feat_test, data.matrix(hp_feat %>% select(-SalePrice_log, -Id))) #predict saleprice_log
#Calculate MSE of 'test' subset of train data
#MSE = 2.128978e-06
MSE.feat = mean((xgb_pred.feat - hp_feat$SalePrice_log) ^ 2)
MSE.feat
#How much is the prediction price off from the actual 'test' price?
pred_dol = exp(xgb_pred.feat) #predicted house price [$]
act_dol = exp(hp_feat$SalePrice_log[-train_idx]) #actual house price (test subset of training dataset) [$]
mean(abs(pred_dol - act_dol))
#Previously, model2 (orig df) outperformed model1 (df)
#Want to combine to maximize best columns
uniq = c(setdiff(names(hp_feat), names(hp_orig)), 'Id')
combined = merge(hp_orig, hp_feat[uniq], by = 'Id')
combined_train = combined[train_idx, ]
#Prep Feature and Response Data
predictors_train = data.matrix(combined_train %>% select(-SalePrice_log, -Id)) #must be matrix
response_train = data.matrix(combined_train %>% select(SalePrice_log, -Id))    #must be matrix
#3rd Model: Combined Variables, No Hyperparameter Tuning
xgb.comb <- xgb.cv(
data = predictors_train,
label = response_train,
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
early_stopping_rounds = 10    #haults CV if MSE doesn't improve
)
#Calculate RMSE of train and test
#RMSE_train = ~0.0212704
#RMSE_test = ~0.1369496
xgb.comb$evaluation_log %>%
summarise(rmse_train   = min(train_rmse_mean),
rmse_test   = min(test_rmse_mean),)
#Plot RMSE vs Number of Trees
ggplot(xgb.orig$evaluation_log) +
geom_line(aes(iter, train_rmse_mean, color = 'Train')) +
geom_line(aes(iter, test_rmse_mean, color = 'Test')) +
labs(x = 'Number of Trees', y = 'RMSE', title = 'Combined Dataset: Train RMSE vs. Number of Trees')
#Create model XGBoost model
xgb.comb_test <- xgboost(
data = predictors_train,
label = response_train,
nrounds = 1000,
#Num of trees
nfold = 5,
#Number of folds (~5-10)
objective = "reg:linear",
#Linear regression
verbose = 0,
#No output
)
#Plot variable importance of 'test' subset of train data
importance_mat.comb = xgb.importance(model = xgb.comb_test)
xgb.plot.importance(importance_mat.comb, top_n = 20, measure = "Gain")
#Predict SalePrice_log of 'test' subset of train data
test_df = data.matrix(combined[-train_idx, ] %>% select(-Id, -SalePrice_log))
xgb_pred.comb = predict(xgb.comb_test, test_df)
#Calculate MSE of 'test' subset of train data
#MSE.comb = 0.01627476
MSE.comb = mean((xgb_pred.comb - combined$SalePrice_log[-train_idx]) ^ 2)
MSE.comb
#How much is the prediction price off from the actual 'test' price?
pred_dol = exp(xgb_pred.comb) #predicted house price [$]
act_dol = exp(combined$SalePrice_log[-train_idx]) #actual house price (test subset of training dataset) [$]
mean(abs(pred_dol - act_dol))
orig_cont = cbind.data.frame(hp_orig[- 'GarageCars'], hp_feat['TotalSF', 'Age', 'AgeRemod', 'TotPorchSF', 'TotCarGarage', 'TotBath'])
orig_cont = cbind.data.frame(hp_orig[-GarageCars], hp_feat[TotalSF, Age, AgeRemod, TotPorchSF, TotCarGarage, TotBath])
orig_cont = cbind.data.frame(hp_orig, hp_feat[TotalSF, Age, AgeRemod, TotPorchSF, TotCarGarage, TotBath])
orig_cont = cbind.data.frame(hp_orig, hp_feat['TotalSF', 'Age', 'AgeRemod', 'TotPorchSF', 'TotCarGarage', 'TotBath'])
df2 = hp_feat %>% select(TotalSf, Age, AgeRemod, TotPorchSF, TotCarGarage, TotBath)
names(hp_feat)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(dplyr)    #data manipulation
library(ggplot2)  #ploting
library(xgboost)  #xgboost for gradient tree model
library(caret)    #for ML
library(dplyr)    #data manipulation
library(ggplot2)  #ploting
library(xgboost)  #xgboost for gradient tree model
